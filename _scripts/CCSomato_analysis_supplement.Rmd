---
title: <font size="5">**Interactions between cardiac activity and conscious somatosensory perception – supplement**</font>
author: <font size="4"> Pawe³ Motyka (pawel.motyka@psych.uw.edu.pl) </font>
date: <font size="2"> Semptember 25th 2018 </font>
output: html_document
chunk_output_type: console
editor_options: 
  chunk_output_type: console
---

&nbsp;
<font size="3">
**List of sections**:

1. Load and preprocess Interoceptive Accuracy data [S1](#S1)
2. Distribution of hits and misses for high and low interoceptive accuracy groups [S2](#S2)
3. Differences in hit rates between systole and diastole for high and low interoceptive accuracy groups [S3](#S3)
4. Differences in hit rates across the three intervals of the cardiac cycle (R-50 to 50, R+250 to R+350, R+550 to R+650) [S4](#S4)
<a name="S1"></a>
&nbsp;

**1. Load and preprocess Interoceptive Accuracy data** </font>


```{r}

# Specify data directory
data_dir <- 'N:/CCSomato_data'
setwd(data_dir)

# load interoceptive accuracy data (Heartbeat Counting Task)
int_acc <- read.csv("CCSomato_HBT.csv", header = TRUE, sep = ";")

# load the preprocessed behavioral and ECG data
data <- read.table("CCSomato_ECG_data(output_from_section_4)", header = TRUE, sep = "\t", fill = TRUE, stringsAsFactors = FALSE)


# calculate averaged interoceptive accuracy from 5 intervals [1/5 sum of (1- (|recorded heartbeats – reported heartbeats|)/recorded heartbeats)]
int_acc$IA <- 0.2 * ((1 - ((abs(int_acc$interval1_measured - int_acc$interval1_counted))/int_acc$interval1_measured)) + (1 - ((abs(int_acc$interval2_measured - int_acc$interval2_counted))/int_acc$interval2_measured)) + (1 - ((abs(int_acc$interval3_measured - int_acc$interval3_counted))/int_acc$interval3_measured)) + (1 - ((abs(int_acc$interval4_measured - int_acc$interval4_counted))/int_acc$interval4_measured)) + (1 - ((abs(int_acc$interval5_measured - int_acc$interval5_counted))/int_acc$interval5_measured)) )

# perform exclusions
int_acc <- int_acc[int_acc$ID != 1,] # exclude participant 1 (one of the authors - piloting)
int_acc <- int_acc[int_acc$ID != 28,] # exclude participant 28 due to not properly reported heartbeats (all zereos)

# Reduce interoceptive accuracy data to ID and IA index
int_acc <- int_acc[, c(col=1, col=18)]

# Summary statistics
mean(int_acc$IA)
sd(int_acc$IA)
range(int_acc$IA)

# Create variable dividing participants into those with higher and lower interoceptive accuracy (by median)
median_IA <- median(int_acc$IA, na.rm = T)
median_IA

int_acc$IA_level[int_acc$IA <= median_IA] <- 'IA_lower' # lower interoceptive accuracy group
int_acc$IA_level[int_acc$IA > median_IA] <- 'IA_higher' # higher interoceptive accuracy group
int_acc$IA_level <- factor(int_acc$IA_level)

# merge data with interoceptive accuracy scores
data_Circ <- merge(data, int_acc, by = 'ID')

# Rayleigh Test yields significant result in case of participant nr 12 indicating a non-uniform distribution of stimulus onsets across the cardiac cycle (RR intervals)
# remove participant nr 12
data_Circ <- data_Circ[data_Circ$ID != 12,] 

```

<a name="S2"></a>
&nbsp;

<font size="3">
**2. Distribution of hits and misses for high and low interoceptive accuracy groups** </font>
&nbsp;

```{r}

require(circular, warn.conflicts = FALSE, quietly = T)
require(scales, warn.conflicts = FALSE, quietly=TRUE)

### Distribtuion of hits within RR intervals

# specify variables containig positions of hits within RR intervals
mean_degree_hit_IA_higher <- vector()
mean_degree_hit_IA_lower <- vector()

# extract the list of participants 
ID_list_IA_higher <- unique(data_Circ$ID[data_Circ$IA_level == "IA_higher"])
ID_list_IA_lower <- unique(data_Circ$ID[data_Circ$IA_level == "IA_lower"])


for (p in ID_list_IA_higher) { # LOOP PARTICIPANTS (p)
  
  # save the vector with hits positions in degrees as a circular object
  temp_hit <- circular(data_Circ$diff2peak_deg[data_Circ$ID==p & data_Circ$resp_class ==   "hit"], type="angles", units="degree", rotation="clock", zero=0)
  
  # calculate the mean phase where hits occurred for the participant
  mean_degree_hit_IA_higher[p] <- mean(temp_hit)
  
} # END: LOOP PARTICIPANTS (p)

for (p in ID_list_IA_lower) { # LOOP PARTICIPANTS (p)
  
  # save the vector with hits positions in degrees as a circular object
  temp_hit <- circular(data_Circ$diff2peak_deg[data_Circ$ID==p & data_Circ$resp_class ==   "hit"], type="angles", units="degree", rotation="clock", zero=0)
  
  # calculate the mean phase where hits occurred for the participant
  mean_degree_hit_IA_lower[p] <- mean(temp_hit)
  
} # END: LOOP PARTICIPANTS (p)


# save the vector with the mean hits for each particiapant as a circular object
Hits_secondlevel_IA_higher <- circular(mean_degree_hit_IA_higher[ID_list_IA_higher], type="angles", units="degree", rotation="clock", zero=pi/2)

Hits_secondlevel_IA_lower <- circular(mean_degree_hit_IA_lower[ID_list_IA_lower], type="angles", units="degree", rotation="clock", zero=pi/2)

# plot the distribution of mean hits within RR interval across participants - with 0 indicating the R peak previous to the stimulus onset
plot(Hits_secondlevel_IA_higher, stack= TRUE , bins = 720, col = alpha("gray10", 0.8), cex = 0.88, lwd = 2, main = "Hits")
points(Hits_secondlevel_IA_lower, col = "gray25", cex = 0.77, lwd = 2)

# add arrows representing mean hits for each participant
arrows.circular(Hits_secondlevel_IA_higher, col =  rgb(0.55, 0.23, 0.23, 0.25), lwd = 3, length = 0.001)
arrows.circular(Hits_secondlevel_IA_lower, col = rgb(0.247, 0.435, 0.545, 0.25), lwd = 3, length = 0.001)

# add an arrow representing grand mean for hits - with its length signifying resultant length of the grand mean
arrows.circular(mean(Hits_secondlevel_IA_higher), y=rho.circular(Hits_secondlevel_IA_higher), lwd = 3, col = rgb(0.45, 0.13, 0.13, 0.75), length = 0.08)
arrows.circular(mean(Hits_secondlevel_IA_lower), y=rho.circular(Hits_secondlevel_IA_lower), lwd = 3, col = rgb(0.147, 0.285, 0.395, 0.75), length = 0.08)

# add line signifying distribution of hits (bandwidth = 20)
circ.dens = density(Hits_secondlevel_IA_higher, bw=20)
lines(circ.dens, col= rgb(0.55, 0.23, 0.23), lwd = 1.5, xpd=TRUE)

circ.dens = density(Hits_secondlevel_IA_lower, bw=20)
lines(circ.dens, col= rgb(0.247, 0.435, 0.545), lwd = 1.5, xpd=TRUE)

# show the angle of grand mean for hits
mean(Hits_secondlevel_IA_higher)
mean(Hits_secondlevel_IA_lower)

# Test for a Common Distribution - two independent samples (p < 0.05 - interpreted as an evidence that directions have been drawn from different distributions)
watson.two.test(Hits_secondlevel_IA_higher, Hits_secondlevel_IA_lower, alpha = 0.05)

# test uniformity of hits distribution within RR intervals
rayleigh.test(Hits_secondlevel_IA_higher)
rayleigh.test(Hits_secondlevel_IA_lower)


### Distribtuion of misses within RR interval

# specify variables containig positions of misses within RR intervals
mean_degree_miss_IA_higher <- vector()
mean_degree_miss_IA_lower <- vector()

for (p in ID_list_IA_higher) { # LOOP PARTICIPANTS (p)
  
  # save the vector with misses positions in degrees as a circular object
  temp_miss <- circular(data_Circ$diff2peak_deg[data_Circ$ID==p & data_Circ$resp_class == "miss"], type="angles", units="degree", rotation="clock", zero=0)
  
  # calculate the mean phase where misses occurred for the participant
  mean_degree_miss_IA_higher[p] <- mean(temp_miss)
  
} # END: LOOP PARTICIPANTS (p)

for (p in ID_list_IA_lower) { # LOOP PARTICIPANTS (p)
  
  # save the vector with misses positions in degrees as a circular object
  temp_miss <- circular(data_Circ$diff2peak_deg[data_Circ$ID==p & data_Circ$resp_class == "miss"], type="angles", units="degree", rotation="clock", zero=0)
  
  # calculate the mean phase where misses occurred for the participant
  mean_degree_miss_IA_lower[p] <- mean(temp_miss)
  
} # END: LOOP PARTICIPANTS (p)

# save the vector with the mean misses for each particiapant as a circular object
misses_secondlevel_IA_higher <- circular(mean_degree_miss_IA_higher[ID_list_IA_higher], type="angles", units="degree", rotation="clock", zero=pi/2)

misses_secondlevel_IA_lower <- circular(mean_degree_miss_IA_lower[ID_list_IA_lower], type="angles", units="degree", rotation="clock", zero=pi/2)

# plot the distribution of mean misses within RR interval across participants - with 0 indicating the R peak previous to the stimulus onset
plot(misses_secondlevel_IA_higher, stack=TRUE, bins = 720, col = alpha("gray10", 0.8), cex = 0.88, lwd = 2, main = "Misses")
points(misses_secondlevel_IA_lower, col = "gray25", cex = 0.77, lwd = 2)

# add arrows representing mean Misses for each participant
arrows.circular(misses_secondlevel_IA_higher, col =  rgb(0.55, 0.23, 0.23, 0.25), lwd = 3, length = 0.001)
arrows.circular(misses_secondlevel_IA_lower, col = rgb(0.247, 0.435, 0.545, 0.25), lwd = 3, length = 0.001)

# add an arrow representing grand mean for Misses - with its length signifying resultant length of the grand mean
arrows.circular(mean(misses_secondlevel_IA_higher), y=rho.circular(misses_secondlevel_IA_higher), lwd = 3, col = rgb(0.45, 0.13, 0.13, 0.76), length = 0.08)
arrows.circular(mean(misses_secondlevel_IA_lower), y=rho.circular(misses_secondlevel_IA_lower), lwd = 3, col = rgb(0.147, 0.285, 0.395, 0.76), length = 0.08)

# add line signifying distribution of Misses (bandwidth = 20)
circ.dens = density(misses_secondlevel_IA_higher, bw=20)
lines(circ.dens, col=rgb(0.55, 0.23, 0.23), lwd = 1.5, xpd=TRUE)

circ.dens = density(misses_secondlevel_IA_lower, bw=20)
lines(circ.dens, col=rgb(0.247, 0.435, 0.545), lwd = 1.5, xpd=TRUE)

# show the angle of grand mean for Misses
mean(misses_secondlevel_IA_higher)
mean(misses_secondlevel_IA_lower)

# Test for a Common Distribution - two independent samples (p < 0.05 - interpreted as an evidence that directions have been drawn from different distributions)
watson.two.test(misses_secondlevel_IA_higher, misses_secondlevel_IA_lower, alpha = 0.05)

# test uniformity of misses distribution within RR intervals
rayleigh.test(misses_secondlevel_IA_higher)
rayleigh.test(misses_secondlevel_IA_lower)


### Test correlation between mean resultant lengths (i.e., the level of hits or misses concentration) and interoceptive accuracy

## Hits

Hits <- data.frame(concentration = numeric(0),
                             IA = numeric(0))

for (p in unique(data_Circ$ID)) { # LOOP PARTICIPANTS (p)
  
  # save the vector with hits positions in degrees as a circular object
  temp_hit <- circular(data_Circ$diff2peak_deg[data_Circ$ID==p & data_Circ$resp_class == "hit"], type="angles", units="degree", rotation="clock",    zero=0)
  
  # save the results of Rayleigh test
  hits_distribution_individual <- rayleigh.test(temp_hit) 
  
  # save the value of mean resultant length 
  concentration <- hits_distribution_individual$statistic
  
  # save IA score
  IA <- unique(data_Circ$IA[data_Circ$ID == p])
  
  # create data frame
   Hits[nrow(Hits)+1,] <- c(concentration, IA)
  
}

# test normality of the variables
shapiro.test(Hits$IA)
shapiro.test(Hits$concentration)

# test correlation between hits concetration and interoceptive accuracy 
cor.test(Hits$IA, Hits$concentration, method ="pearson")

## Misses

Misses <- data.frame(concentration = numeric(0),
                             IA = numeric(0))

for (p in unique(data_Circ$ID)) { # LOOP PARTICIPANTS (p)
  
   # save the vector with Misses positions in degrees as a circular object
  temp_hit <- circular(data_Circ$diff2peak_deg[data_Circ$ID==p & data_Circ$resp_class == "miss"], type="angles", units="degree", rotation="clock", zero=0)
  
  # save the results of Rayleigh test
  Misses_distribution_individual <- rayleigh.test(temp_hit) 
  
  # save the value of mean resultant length
  concentration <- Misses_distribution_individual$statistic
  
  #  save IA score
  IA <- unique(data_Circ$IA[data_Circ$ID == p])
  
  # create data frame
   Misses[nrow(Misses)+1,] <- c(concentration, IA)
  
}

# test normality of the variables
shapiro.test(Misses$IA)
shapiro.test(Misses$concentration)

# test correlation between Misses concetration and interoceptive accuracy 
cor.test(Misses$IA, Misses$concentration, method ="pearson")



```

<a name="S3"></a>

&nbsp;

<font size="3">
**3. Differences in hit rates between systole and diastole for high and low interoceptive accuracy groups** </font> &nbsp;
```{r, fig.height= 5, fig.width= 5}

# load preprocessed data
data <- read.table("CCSomato_ECG_data(output_from_section_7)", header = TRUE, sep = "\t", fill = TRUE, stringsAsFactors = FALSE)

require(ggplot2, warn.conflicts = FALSE, quietly=TRUE)
require(effsize, warn.conflicts = FALSE, quietly=TRUE)
require(scales, warn.conflicts = FALSE, quietly=TRUE)
require(car, warn.conflicts = FALSE, quietly=TRUE)
require(ez, warn.conflicts = FALSE, quietly=TRUE)
require(tidyr, warn.conflicts = FALSE, quietly=TRUE)

data_ID <- data.frame(ID = integer(0),
                 hit_rate = numeric(0),
                 hit_rate_s = numeric(0), # hit rate at systole
                 hit_rate_d = numeric(0)) # hit rate at diastole


for ( p in unique(data$ID)) { # LOOP PARTICIPANTS (p)
    
    # calculate hit rate
    hit_rate <- (length(data$resp_class[data$resp_class =="hit" & data$ID == p]))/(length(data$trial[data$ID == p & data$stim_type == 1]))
    
   
    # calculate hit rate at systole
    hit_rate_s <- (length(data$resp_class[data$resp_class =="hit" & data$ID == p & data$systole == T]))/(length(data$trial[data$ID == p & data$stim_type == 1 & data$systole == T]))
    
    # calculate hit rate at diastole
    hit_rate_d <- (length(data$resp_class[data$resp_class =="hit" & data$ID == p & data$systole == F]))/(length(data$trial[data$ID == p & data$stim_type == 1 & data$systole == F]))

    # add calculated varialbes to the data frame
    data_ID[nrow(data_ID)+1,] <- c(p, hit_rate, hit_rate_s,hit_rate_d)
    
} # END: LOOP PARTICIPANTS (p)

data_ID$hit_rate <- data_ID$hit_rate * 100
data_ID$hit_rate_s <- data_ID$hit_rate_s * 100
data_ID$hit_rate_d <- data_ID$hit_rate_d * 100

# test normality of hit rate distribution at systole and diastole
shapiro.test(data_ID$hit_rate_s)
shapiro.test(data_ID$hit_rate_d)

# merge data frames
data_ID <- merge(int_acc, data_ID, by = 'ID')


### Run Two-way mixed ANOVA

data_ID <- data_ID[, c(col=c(1,3,5,6))]

dat <- gather(data_ID, phase, hit_rate, hit_rate_s:hit_rate_d, factor_key = T)
dat$ID <- as.factor(dat$ID)

#ezAnova method
anova_ez = ezANOVA(data=dat, wid=ID, dv = hit_rate, within = phase, between=IA_level, detailed = TRUE)
print(anova_ez)

### Plot

# save data as vectors
s_hit_rate_high <- data_ID$hit_rate_s[data_ID$IA_level == "IA_higher"] 
d_hit_rate_high <- data_ID$hit_rate_d[data_ID$IA_level == "IA_higher"] 
s_hit_rate_low <- data_ID$hit_rate_s[data_ID$IA_level == "IA_lower"] 
d_hit_rate_low <- data_ID$hit_rate_d[data_ID$IA_level == "IA_lower"] 

par(pty="s")

# specify plotting space
plot(c(0,109),c(0,109),type="n",xlab ="", ylab="", cex.lab = 0.8, cex.axis = 0.8, frame.plot = F)

title(ylab="Hit rate at systole (%)", line = 2.5, cex.lab= 0.8)
title(xlab="Hit rate at diastole (%)", line = 2.5, cex.lab= 0.8)

# create an identity line using a customized linear model
x<-0:100
y<-0:100
new <- data.frame(x = seq(0, 100, 0.5))
lines(new$x, predict(lm(y~x), new),col= alpha("black", alpha = 0.8),lty= 2, lwd = 1.3)

# plot the individual data
points(d_hit_rate_high, s_hit_rate_high, pch = 1, col = rgb(0.55, 0.23, 0.23), cex = 1) # higher IA group
points(d_hit_rate_low, s_hit_rate_low, pch = 1, col = rgb(0.247, 0.435, 0.545), cex = 1) # lower IA group


# prepare the matrix with sensitivity distribution (difference between sensitivity at systole and diastole)
diff_high <- as.matrix(data.frame(x=density(d_hit_rate_high-s_hit_rate_high)$x,y=density(d_hit_rate_high-s_hit_rate_high)$y))
diff_low <- as.matrix(data.frame(x=density(d_hit_rate_low-s_hit_rate_low)$x,y=density(d_hit_rate_low-s_hit_rate_low)$y))

# rescale y axis to match size of the plot
f <- scales::rescale(diff_high[,2], to = c(0, 20))
diff_high <- as.matrix(data.frame(x=density(d_hit_rate_high-s_hit_rate_high)$x,y=f))

f2 <- scales::rescale(diff_low[,2], to = c(0, 20))
diff_low <- as.matrix(data.frame(x=density(d_hit_rate_low-s_hit_rate_low)$x,y=f2))

# prepare rotation parameters
rotation_matrix <- matrix(c(cospi(1/4),sinpi(1/4),-sinpi(1/4),cospi(1/4)),ncol=2)

# rotate the matrix with sensitivity distribution 
diff_high_rotated <- diff_high %*% rotation_matrix
diff_low_rotated <- diff_low %*% rotation_matrix

# plot hit rate distribution
lines((diff_high_rotated)+90, col = rgb(0.55, 0.23, 0.23), lwd = 1.7)
lines((diff_low_rotated)+90, col = rgb(0.247, 0.435, 0.545), lwd = 1.7)

# create the x axis
lines(c(74,103.4),c(103.4,74), col = "black", cex = 1)

# define the coordinates representing the values plotted on the x axis
points_coordinates <- matrix(c(1,0,-1,0),nrow=2,byrow=T)

# rotate the coordinates
points_coordinates_rotated <- points_coordinates %*% rotation_matrix

# add units to x axis
text(points_coordinates_rotated[1,1]+92,points_coordinates_rotated[1,2]+77,"+10%",srt=315,cex=.7)
text(points_coordinates_rotated[1,1]+103,points_coordinates_rotated[1,2]+74.7,"|",srt=315,cex=.8)
text(points_coordinates_rotated[2,1]+77,points_coordinates_rotated[2,2]+92,"-10%",srt=315,cex=.7)
text(points_coordinates_rotated[2,1]+74.7,points_coordinates_rotated[2,2]+103,"|",srt=315,cex=.8)

# add endpoints to x axis
text(points_coordinates_rotated[1,1]+94.7,points_coordinates_rotated[1,1]+80,"|",srt=315, cex= 0.35, col = "black")
text(points_coordinates_rotated[1,1]+80,points_coordinates_rotated[1,1]+94.7,"|",srt=315, cex= 0.35, col = "black")


```

<a name="S4"></a>

&nbsp;

<font size="3">
**4. Differences in hit rates across the three intervals of the cardiac cycle (R-50 to 50, R+250 to R+350, R+550 to R+650)** </font> &nbsp;


```{r}

# load the preprocessed behavioral and ECG data (before the exclusion of trials with outyling t-waves used in the binary analysis)
data <- read.table("CCSomato_ECG_data(output_from_section_4)", header = TRUE, sep = "\t", fill = TRUE, stringsAsFactors = FALSE)

require(ggplot2, warn.conflicts = FALSE, quietly=TRUE)
require(scales, warn.conflicts = FALSE, quietly=TRUE)
require(lme4, warn.conflicts = FALSE, quietly=TRUE)
require(tidyr, warn.conflicts = FALSE, quietly=TRUE)
require(afex, warn.conflicts = FALSE, quietly=TRUE)
require(plyr, warn.conflicts = FALSE, quietly=TRUE)
require(emmeans, warn.conflicts = FALSE, quietly=TRUE)

# show how many RR intervals are shorter 0.7 s 
length(data$RR_interval[data$RR_interval < 0.700])

# derive number of RR intervals are shorter than 0.7 s for each subject
d <- data.frame(ID = integer(0), cases = numeric(0)) 
  for (i in unique(data$ID)) {
  cases <- length(data$ID[data$RR_interval < 0.700 & data$ID == i])  
  d[nrow(d) + 1,] <- c(i, cases)
}

# calculate proportion of RR Intervals shorter than 0.7 s
d$proportion <- d$cases / 360

# get participants with more than 30% of RR Intervals shorter than 0.7 s
exclude <- unique(d$ID[d$proportion > 0.3])
exclude

# exclude these participants from data
data <- subset(data, !(data$ID %in% exclude))

# show remaining RR intervals shorter than 0.7
length(data$ID[data$RR_interval < 0.700])

# show number of participants concerned
length(unique(data$ID[data$RR_interval < 0.700]))

# statistics of excluded trials in the concerned group of participants
d <- subset(d, !(d$ID %in% exclude))
exclude <- unique(d$ID[d$proportion == 0])
d <- subset(d, !(d$ID %in% exclude))
mean(d$cases)
sd(d$cases)
range(d$cases)

# exclude remaining RR intervals shorter than 0.7
data <- data[data$RR_interval > 0.700, ]

# recalculate the stimulus onset position up to 50 ms before the R peak into minus values (R -50 to 0 ms) while keeping the other stimulus onset positions unchanged. 
for ( i in unique(data$ID)) {
  for (b in unique(data$block[data$ID == i])) {
    for (t in unique(data$trial[data$ID == i & data$block == b])) {
  
ifelse((data$RR_interval[data$ID == i & data$block == b & data$trial == t] - data$diff2peak_abs[data$ID == i & data$block == b & data$trial == t]) > 0.050, data$diff2peak_abs_alt[data$ID == i & data$block == b & data$trial == t] <- data$diff2peak_abs[data$ID == i & data$block == b & data$trial == t], data$diff2peak_abs_alt[data$ID == i & data$block == b & data$trial == t] <- data$diff2peak_abs[data$ID == i & data$block == b & data$trial == t] - data$RR_interval[data$ID == i & data$block == b & data$trial == t])
    }
  }
}

# calculate hit rates for different intervals of the cardiac cycle
data_IDs <- data.frame(ID = integer(0),
                 hit_rate_R0 = numeric (0), # R-50 to R+50
                 hit_rate_R300 = numeric(0), # R+250 to R+350
                 hit_rate_R600 = numeric(0), # R+550 to R+650
                 hit_rate = numeric(0),
                 R0_trials = numeric(0), # number of trials
                 R300_trials = numeric(0), 
                 R600_trials = numeric(0))

for ( p in unique(data$ID)) { # LOOP PARTICIPANTS (p)
    
    # calculate hit rate at R-50 to R+50
    hit_rate_R0 <- (length(data$resp_class[data$resp_class =="hit" & data$ID == p & data$diff2peak_abs_alt >= -0.05 & data$diff2peak_abs_alt <= 0.05]))/(length(data$trial[data$ID == p & data$stim_type == 1 & data$diff2peak_abs_alt >= -0.05 & data$diff2peak_abs_alt <= 0.05]))
    
    # calculate hit rate at R+250 to R+350
    hit_rate_R300 <- (length(data$resp_class[data$resp_class =="hit" & data$ID == p & data$diff2peak_abs_alt >= 0.25 & data$diff2peak_abs_alt <= 0.35]))/(length(data$trial[data$ID == p & data$stim_type == 1 & data$diff2peak_abs_alt >= 0.25 & data$diff2peak_abs_alt <= 0.35]))
    
    # calculate hit rate at # R+550 to R+650
    hit_rate_R600 <- (length(data$resp_class[data$resp_class =="hit" & data$ID == p & data$diff2peak_abs_alt >= 0.55 & data$diff2peak_abs_alt <= 0.65]))/(length(data$trial[data$ID == p & data$stim_type == 1 & data$diff2peak_abs_alt >= 0.55 & data$diff2peak_abs_alt <= 0.65]))

    # calculate hit rate 
    hit_rate <- (length(data$resp_class[data$resp_class =="hit" & data$ID == p]))/(length(data$trial[data$ID == p & data$stim_type == 1]))
    
    #number of trials within each interval
    R0_trials <- length(data$trial[data$ID == p & data$stim_type == 1 & data$diff2peak_abs_alt >= -0.05 & data$diff2peak_abs_alt <= 0.05])
    R300_trials <- length(data$trial[data$ID == p & data$stim_type == 1 & data$diff2peak_abs_alt >= 0.25 & data$diff2peak_abs_alt <= 0.35])
    R600_trials <- length(data$trial[data$ID == p & data$stim_type == 1 & data$diff2peak_abs_alt >= 0.55 & data$diff2peak_abs_alt <= 0.65])
    
    # add calculated varialbes to the data frame
    data_IDs[nrow(data_IDs)+1,] <- c(p, hit_rate_R0, hit_rate_R300, hit_rate_R600, hit_rate, R0_trials, R300_trials, R600_trials)
    
} # END: LOOP PARTICIPANTS (p)

# number of trials within each interval
mean(data_IDs$R0_trials)
range(data_IDs$R0_trials)
mean(data_IDs$R300_trials)
range(data_IDs$R300_trials)
mean(data_IDs$R600_trials)
range(data_IDs$R600_trials)

# Check the equality of trials with the chi-square goodness-of-fit test
R0 <- mean(data_IDs$R0_trials)
R300 <- mean(data_IDs$R300_trials)
R600 <- mean(data_IDs$R600_trials)
chisq.test(c(R0,R300,R600), y = NULL, correct = F, p = c(1/3, 1/3, 1/3))

# hit rates into %
data_IDs$hit_rate_R0 <- data_IDs$hit_rate_R0 * 100
data_IDs$hit_rate_R300 <- data_IDs$hit_rate_R300 * 100
data_IDs$hit_rate_R600 <- data_IDs$hit_rate_R600 * 100

# test normality of hit rates distribution
shapiro.test(data_IDs$hit_rate_R0)
shapiro.test(data_IDs$hit_rate_R300)
shapiro.test(data_IDs$hit_rate_R600)

# get mean hit rates
mean(data_IDs$hit_rate_R0)
mean(data_IDs$hit_rate_R300)
mean(data_IDs$hit_rate_R600)
grand_mean <- mean(data_IDs$hit_rate) * 100

## Prepare the data frame for repeated measures ANOVA

#remove trials data
data_IDs <- data_IDs[,1:4]

# reshape the data frame
dat <- gather(data_IDs, key = "time", value = "hit rate", -ID)
dat$time <- factor(dat$time)

## Perform Repeated measures ANOVA
# to see uncorrected degrees of freedom
fit_all <- aov_ez("ID","hit rate", dat, within=c("time"), return = "nice")
fit_all
# corrected degrees of freedom
fit_all <- aov_ez("ID","hit rate", dat, within=c("time"))
fit_all
# summary
summary(fit_all) # see epsilon values

# Calculate confidence intervals
ref <- emmeans::emmeans(fit_all, specs = c("time"))
 
# Post-hoc Bonferroni-corrected paired t tests. 
emmeans::contrast(ref,method="pairwise",adjust="bonferroni")

## Define three functions used to calculate within-subjects variation. These fragments of code are credited to Winston Chang and were used and copied here under the CC0 license (http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/#understanding-within-subjects-error-bars)

# Function 1: normDataWithin

normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL, na.rm=FALSE, .drop=TRUE) {
    library(plyr)

    # Measure var on left, idvar + between vars on right of formula.
    data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
     .fun = function(xx, col, na.rm) {
        c(subjMean = mean(xx[,col], na.rm=na.rm))
      },
      measurevar,
      na.rm
    )

    # Put the subject means with original data
    data <- merge(data, data.subjMean)

    # Get the normalized data in a new column
    measureNormedVar <- paste(measurevar, "_norm", sep="")
    data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
                               mean(data[,measurevar], na.rm=na.rm)

    # Remove this subject mean column
    data$subjMean <- NULL

    return(data)
}

# Function 2: summarySEwithin

summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL, idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {

  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
    FUN=is.factor, FUN.VALUE=logical(1))

  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }

  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL

  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)

  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")

  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                           FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )

  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor

  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}

# Function 3: summarySE

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}

# change name
colnames(dat)[colnames(dat)=="hit rate"] <- "hit_rate"
dat$time <- factor(dat$time)

# Calculate within-subjects variation in hit rates across the intervals
d <- summarySEwithin(data=dat, measurevar = "hit_rate", betweenvars= NULL, withinvars=c("time"), idvar="ID", na.rm=FALSE, conf.interval=.95, .drop= TRUE)

# Save time as factor
d$time <- factor(d$time)

# prepare parameters for plotting
dodge <- position_dodge(width = 0.9)
limits <- aes(ymax = d$hit_rate + d$ci,
              ymin = d$hit_rate - d$ci)
labs <- c("R+0", "R+300", "R+600")
bold.text <- element_text(face = "bold", color = "black")

FigS3 <- ggplot(data = d, aes(x = time, y = hit_rate, fill = time)) + geom_bar(stat = "identity", width = 0.74, position = dodge) +
  geom_errorbar(limits, position = dodge, width = 0.15) +
  scale_fill_manual(values=c(rgb(0.23,0.48,0.50, 0.6), rgb(0.23,0.48,0.50, 0.6), rgb(0.23,0.48,0.50, 0.6))) +
  theme_classic() + 
  scale_y_continuous(limits=c(0,60), expand = expand_scale(mult = c(0, .05))) +
  scale_x_discrete(labels=labs) +
  labs(x = "Intervals of the cardiac cycle (ms)", y = "Hit rate (%)") +
  theme(legend.position="none", axis.title.y = element_text(margin = margin(t = 0, r = 15, b = 0, l = 0)), axis.title.x = element_text(margin = margin(t = 15, r = 0, b = 0, l = 0)), axis.text.x = element_text(margin = margin(t = 7, r = 0, b = 0, l = 0)), axis.text=element_text(size=20), axis.title=element_text(size=22)) + 
  theme(axis.title = bold.text) 

#exported size: 8x8 cm
print(FigS3)


```

